<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>K-Nearest Neighbour (KNN) from scratch | Hi, I am PQ Tan ☃️</title> <meta name="author" content="Hi, I am PQ Tan ☃️"> <meta name="description" content="Writing KNN functions from scratch to classify abalone into different classes based on their age."> <meta name="keywords" content="mono-pq, github portfolio, portfolio, data analyst, data science, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%91%A9%F0%9F%8F%BB%E2%80%8D%F0%9F%92%BB&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://mono-pq.github.io/projects/0_project/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Hi, I am </span>PQ Tan ☃️</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">K-Nearest Neighbour (KNN) from scratch</h1> <p class="post-description">Writing KNN functions from scratch to classify abalone into different classes based on their age.</p> </header> <article> <h3 id="tldr">TL;DR</h3> <p>Writing KNN algorithms to classify abalone based on their age with an accuracy of 27.614% (n=20). The low accuracy may be due to imbalanced data set as 17 of 29 classes have less than a hundred data points resulting in insufficient data to train the model accurately. Data originates from <a href="https://archive.ics.uci.edu/ml/datasets/Abalone" rel="external nofollow noopener" target="_blank">UCI Machine Learning Repository</a>.</p> <p>Refer to <a href="https://github.com/Mono-PQ/course_work/tree/main/4_k-nearest-neighbours" rel="external nofollow noopener" target="_blank">k-nearest-neigbour github repo</a> for more details.</p> <h3 id="introduction">Introduction</h3> <p><strong>Classification</strong> problem refers to grouping similar data or classifying data by specific categories using a predetermined set of features. The output of a classification problem has discrete value represented by an integer.</p> <p>In this project, we’ll attempt to classify the age of abalone into 15 classes (i.e., rings) using the following features.</p> <table> <thead> <tr> <th>Features</th> <th>Data Type</th> <th>Measures</th> <th>Description</th> </tr> </thead> <tbody> <tr> <td>Sex</td> <td>Nominal</td> <td>M, F, I (Infant)</td> <td>Nil</td> </tr> <tr> <td>Length</td> <td>Continuous</td> <td>mm</td> <td>Longest shell measurement</td> </tr> <tr> <td>Diameter</td> <td>Continuous</td> <td>mm</td> <td>Perpendicular to length</td> </tr> <tr> <td>Height</td> <td>Continuous</td> <td>mm</td> <td>With meat in shell</td> </tr> <tr> <td>Whole weight</td> <td>Continuous</td> <td>grams</td> <td>Whole abalone</td> </tr> <tr> <td>Shucked weight</td> <td>Continuous</td> <td>grams</td> <td>Weight of meat</td> </tr> <tr> <td>Viscera weight</td> <td>Continuous</td> <td>grams</td> <td>Gut weight (after bleeding)</td> </tr> <tr> <td>Shell weight</td> <td>Continuous</td> <td>grams</td> <td>After being dried</td> </tr> </tbody> </table> <p><br></p> <h3 id="k-nearest-neighbours-knn">K-Nearest Neighbours (KNN)</h3> <p>The KNN algorithm assumes that similar data points exist in close proximity. The neighbouring data points are used to predict the outcome of the the new data point by choosing the most common categories for classification problems or mean of the neighbours for regression problems. <code class="language-plaintext highlighter-rouge">K</code> represents the number of neighbours used to predict the outcome.</p> \[EuclideanDistance = d(p,q) = \sqrt{(p_1 - q_1)^2 + (p_2 - q_2)^2 + ... + (p_n - q_n)^2}\] <p>Normalisation of data points when using KNN for prediction is important to ensure that the distance is not being influenced by features with higher scale of measurements that could result in misclassifications. KNN is distance dependent, where more weight is given to higher scaled feature.</p> <p>Python code for KNN algorithm, train-test-split and K-fold:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">def</span> <span class="nf">loadData</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
    <span class="c1"># Load data from file into X
</span>    <span class="n">X</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="n">text_file</span> <span class="o">=</span> <span class="nf">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="sh">"</span><span class="s">r</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">lines</span> <span class="o">=</span> <span class="n">text_file</span><span class="p">.</span><span class="nf">readlines</span><span class="p">()</span>
        
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">:</span>
        <span class="n">X</span><span class="p">.</span><span class="nf">append</span><span class="p">([])</span>
        <span class="n">words</span> <span class="o">=</span> <span class="n">line</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s">,</span><span class="sh">"</span><span class="p">)</span>
        <span class="c1"># Convert values of the first attribute into float
</span>        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
            <span class="nf">if </span><span class="p">(</span><span class="n">word</span><span class="o">==</span><span class="sh">'</span><span class="s">M</span><span class="sh">'</span><span class="p">):</span>
                <span class="n">word</span> <span class="o">=</span> <span class="mf">0.333</span>
            <span class="nf">if </span><span class="p">(</span><span class="n">word</span><span class="o">==</span><span class="sh">'</span><span class="s">F</span><span class="sh">'</span><span class="p">):</span>
                <span class="n">word</span> <span class="o">=</span> <span class="mf">0.666</span>
            <span class="nf">if </span><span class="p">(</span><span class="n">word</span><span class="o">==</span><span class="sh">'</span><span class="s">I</span><span class="sh">'</span><span class="p">):</span>
                <span class="n">word</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="n">X</span><span class="p">[</span><span class="n">count</span><span class="p">].</span><span class="nf">append</span><span class="p">(</span><span class="nf">float</span><span class="p">(</span><span class="n">word</span><span class="p">))</span>
        <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
    
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">testNorm</span><span class="p">(</span><span class="n">X_norm</span><span class="p">):</span>
    <span class="n">xMerged</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">copy</span><span class="p">(</span><span class="n">X_norm</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="c1"># Merge datasets
</span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">X_norm</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">xMerged</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">((</span><span class="n">xMerged</span><span class="p">,</span><span class="n">X_norm</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]))</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">xMerged</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">xMerged</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">dataNorm</span><span class="p">(</span><span class="n">X</span><span class="p">):</span> 
    <span class="c1"># Normalise data points for first 8 columns
</span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">8</span><span class="p">):</span> 
        <span class="n">col</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span>
        <span class="n">max_val</span> <span class="o">=</span> <span class="n">col</span><span class="p">.</span><span class="nf">max</span><span class="p">()</span> 
        <span class="n">min_val</span> <span class="o">=</span> <span class="n">col</span><span class="p">.</span><span class="nf">min</span><span class="p">()</span> 
        <span class="n">X</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">col</span><span class="o">-</span><span class="n">min_val</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">max_val</span><span class="o">-</span><span class="n">min_val</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">X</span>

<span class="k">def</span> <span class="nf">splitTT</span><span class="p">(</span><span class="n">X_norm</span><span class="p">,</span> <span class="n">percentTrain</span><span class="p">):</span> 
    <span class="c1"># Split dataset into train and test set based on the percentTrain specified
</span>    <span class="c1"># Random shuffling of data before splitting
</span>    <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">shuffle</span><span class="p">(</span><span class="n">X_norm</span><span class="p">)</span>
    <span class="c1"># Get index to split the data and slice the dataset based on the index
</span>    <span class="n">index</span> <span class="o">=</span> <span class="nf">round</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">X_norm</span><span class="p">)</span><span class="o">*</span><span class="n">percentTrain</span><span class="p">)</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X_norm</span><span class="p">[:</span><span class="n">index</span><span class="p">,:],</span> <span class="n">X_norm</span><span class="p">[</span><span class="n">index</span><span class="p">:,:]</span>
    <span class="n">X_split</span> <span class="o">=</span> <span class="p">[</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">X_split</span>

<span class="k">def</span> <span class="nf">splitCV</span><span class="p">(</span><span class="n">X_norm</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span> 
    <span class="c1"># Partition dataset into k-folds based on k (i.e., number of partitions) specified
</span>    <span class="c1"># Random shuffling of data before partitioning
</span>    <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">shuffle</span><span class="p">(</span><span class="n">X_norm</span><span class="p">)</span>
    <span class="n">X_split</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># Get the approx. size for each fold
</span>    <span class="n">size</span> <span class="o">=</span> <span class="nf">round</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">X_norm</span><span class="p">)</span><span class="o">/</span><span class="n">k</span><span class="p">)</span>
    <span class="c1"># Partition the data based on the size. The remaining data points will be added to the arrays 
</span>    <span class="c1"># and attempt to make the size of each array equal. Remaining data points would be left unused. 
</span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span> 
        <span class="n">X_split</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">X_norm</span><span class="p">[:</span><span class="n">size</span><span class="p">,:])</span>
        <span class="n">X_norm</span> <span class="o">=</span> <span class="n">X_norm</span><span class="p">[</span><span class="n">size</span><span class="p">:,:]</span>
    <span class="c1"># If there are limited data points, the following code could be use to add the remaining data points 
</span>    <span class="c1"># to the partitions: (Extra)
</span>    <span class="c1"># if len(X_norm) != 0:
</span>    <span class="c1">#     i = 0
</span>    <span class="c1">#     for elem in X_norm:
</span>    <span class="c1">#         X_split[i] = list(X_split[i])
</span>    <span class="c1">#         X_split[i].append(elem)
</span>    <span class="c1">#         X_split[i] = np.array(X_split[i])
</span>    <span class="c1">#         i+=1
</span>    <span class="k">return</span> <span class="n">X_split</span>

<span class="k">def</span> <span class="nf">knn</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">K</span><span class="p">):</span> 
    <span class="n">predictions</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># Generate prediction for X_test
</span>    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">X_test</span><span class="p">:</span>
        <span class="c1"># Calculate the distance of the data points in X_train for each data point in X_test 
</span>        <span class="n">distances</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">row_train</span> <span class="ow">in</span> <span class="n">X_train</span><span class="p">:</span>
            <span class="n">distance</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="c1"># Calculated distance based on Euclidean distance
</span>            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">row</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
                <span class="n">distance</span> <span class="o">+=</span> <span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">row_train</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">**</span><span class="mi">2</span>
            <span class="n">distance</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">distance</span><span class="p">)</span>
            <span class="n">distances</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="n">row_train</span><span class="p">,</span> <span class="n">distance</span><span class="p">))</span>
        <span class="c1"># Sort the distances for the data point of X_test
</span>        <span class="n">distances</span><span class="p">.</span><span class="nf">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">elem</span><span class="p">:</span> <span class="n">elem</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="c1"># Get the "K" (specified number of neighbours) and predict the class for that data point
</span>        <span class="n">neighbours</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
            <span class="n">neighbours</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">distances</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">output_vals</span> <span class="o">=</span> <span class="p">[</span><span class="n">n</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">neighbours</span><span class="p">]</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="nf">set</span><span class="p">(</span><span class="n">output_vals</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="n">output_vals</span><span class="p">.</span><span class="n">count</span><span class="p">)</span>
        <span class="n">predictions</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">prediction</span><span class="p">)</span>
    <span class="c1"># Calculate the accuracy of the prediction (no. accurate predictions / total predictions)
</span>    <span class="n">accurate_pred</span> <span class="o">=</span> <span class="mi">0</span> 
    <span class="n">pred_count</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
    <span class="n">actual</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">pred_count</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">predictions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">actual</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
            <span class="n">accurate_pred</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">accurate_pred</span><span class="o">/</span><span class="n">pred_count</span><span class="p">)</span> <span class="o">*</span> <span class="mf">100.00</span>
    <span class="k">return</span> <span class="n">accuracy</span>

<span class="c1"># This is an example the main of KNN with train-and-test + Euclidean
</span><span class="k">def</span> <span class="nf">knnMain</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span><span class="n">percentTrain</span><span class="p">,</span><span class="n">k</span><span class="p">):</span>
 
    <span class="c1"># Data load
</span>    <span class="n">X</span> <span class="o">=</span> <span class="nf">loadData</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
    <span class="c1"># Normalization
</span>    <span class="n">X_norm</span> <span class="o">=</span> <span class="nf">dataNorm</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="c1"># Data split: train-and-test
</span>    <span class="n">X_split</span> <span class="o">=</span> <span class="nf">splitTT</span><span class="p">(</span><span class="n">X_norm</span><span class="p">,</span><span class="n">percentTrain</span><span class="p">)</span>
    <span class="c1"># KNN: Euclidean
</span>    <span class="n">accuracy</span> <span class="o">=</span> <span class="nf">knn</span><span class="p">(</span><span class="n">X_split</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">X_split</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">k</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">accuracy</span>
</code></pre></div></div> <p><br></p> <h3 id="accuracy">Accuracy</h3> <p>The following accuracy is calculated using the percentage of accurate predictions. Values are rounded up to 3 decimal places.</p> <ul> <li>The highest and lowest accuracy for train-and-test split are 27.614% for 70:30 split where k-neighbour=20 and 18.861% for 50:50 split where k-neighbour=1.</li> <li>The highest and lowest accuracy for k-fold cross validation split are 25.659% for k-fold = 15 where k-neighbour=20 and 18.861% for k-fold=1 where k-neighbour=1.</li> </ul> <table> <thead> <tr> <th>Accuracy</th> <th>Train-and-Test</th> <th> </th> <th> </th> <th>Cross-Validation</th> <th> </th> <th> </th> </tr> </thead> <tbody> <tr> <td> </td> <td>0.7-0.3</td> <td>0.6-0.4</td> <td>0.5-0.5</td> <td>5-fold</td> <td>10-fold</td> <td>15-fold</td> </tr> <tr> <td>K=1</td> <td>19.393%</td> <td>19.270%</td> <td>18.861%</td> <td>19.641%</td> <td>19.895%</td> <td>19.976%</td> </tr> <tr> <td>K=5</td> <td>25.858%</td> <td>24.536%</td> <td>22.882%</td> <td>23.401%</td> <td>22.410%</td> <td>23.285%</td> </tr> <tr> <td>K=10</td> <td>24.741%</td> <td>25.613%</td> <td>25.227%</td> <td>24.048%</td> <td>23.916%</td> <td>24.580%</td> </tr> <tr> <td>K=15</td> <td>26.257%</td> <td>26.272%</td> <td>26.663%</td> <td>25.102%</td> <td>24.731%</td> <td>24.724%</td> </tr> <tr> <td>K=20</td> <td>27.614%</td> <td>27.169%</td> <td>26.472%</td> <td>25.269%</td> <td>25.162%</td> <td>25.659%</td> </tr> </tbody> </table> <p><br></p> <h3 id="run-time">Run Time</h3> <p>The computational time is tabulated using the <code class="language-plaintext highlighter-rouge">timeit</code> library. Values are rounded up to 3 decimal places.</p> <table> <thead> <tr> <th>Computational Time</th> <th>Train-and-Test</th> <th> </th> <th> </th> <th>Cross-Validation</th> <th> </th> <th> </th> </tr> </thead> <tbody> <tr> <td> </td> <td>0.7-0.3</td> <td>0.6-0.4</td> <td>0.5-0.5</td> <td>5-fold</td> <td>10-fold</td> <td>15-fold</td> </tr> <tr> <td>K=1</td> <td>11.969 seconds</td> <td>13.483 seconds</td> <td>14.147 seconds</td> <td>45.429 seconds</td> <td>50.753 seconds</td> <td>52.492 seconds</td> </tr> <tr> <td>K=5</td> <td>12.136 seconds</td> <td>13.474 seconds</td> <td>14.070 seconds</td> <td>45.299 seconds</td> <td>50.434 seconds</td> <td>52.282 seconds</td> </tr> <tr> <td>K=10</td> <td>11.931 seconds</td> <td>13.479 seconds</td> <td>13.972 seconds</td> <td>45.307 seconds</td> <td>50.532 seconds</td> <td>52.689 seconds</td> </tr> <tr> <td>K=15</td> <td>11.906 seconds</td> <td>13.605 seconds</td> <td>13.977 seconds</td> <td>45.840 seconds</td> <td>50.737 seconds</td> <td>52.855 seconds</td> </tr> <tr> <td>K=20</td> <td>11.936 seconds</td> <td>13.662 seconds</td> <td>13.992 seconds</td> <td>45.423 seconds</td> <td>50.601 seconds</td> <td>52.021 seconds</td> </tr> </tbody> </table> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Hi, I am PQ Tan ☃️. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>